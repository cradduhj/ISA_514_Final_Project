{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d445216-bbd5-4606-850a-024655038505",
   "metadata": {},
   "source": [
    "# Decision Tree Modeling\n",
    "## Continuous Response (view_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd453455-bd9c-40f9-aa1d-e70ba143876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /opt/tljh/user/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: statsmodels in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: xgboost in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (3.1.2)\n",
      "Requirement already satisfied: matplotlib in /opt/tljh/user/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /opt/tljh/user/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: imbalanced-learn in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/tljh/user/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/tljh/user/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/tljh/user/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/tljh/user/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/tljh/user/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/tljh/user/lib/python3.12/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (from xgboost) (2.28.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/tljh/user/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/tljh/user/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/tljh/user/lib/python3.12/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/tljh/user/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/tljh/user/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/tljh/user/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/jupyter-cradduhj/.local/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/tljh/user/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/tljh/user/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/tljh/user/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/tljh/user/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# import/install librares/packages\n",
    "!pip install pandas numpy scikit-learn statsmodels xgboost matplotlib seaborn imbalanced-learn\n",
    "!pip install -U scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# initialize scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e5a3fd2-5a91-4beb-b2cf-1d9bc974faba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>view_count</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>Rap_Street_Slang_Topic</th>\n",
       "      <th>Romance_Relationships_Topic</th>\n",
       "      <th>Life_Nostalgia_Topic</th>\n",
       "      <th>Party_Dance_Sensuality_Topic</th>\n",
       "      <th>Love_Emotion_Sentiment_Topic</th>\n",
       "      <th>Loss_Struggle_Reflection_Topic</th>\n",
       "      <th>Energy_Vibes_Epic_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20200</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>-5.745</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>92.960</td>\n",
       "      <td>0.907</td>\n",
       "      <td>1.118930e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>4.846395</td>\n",
       "      <td>98</td>\n",
       "      <td>0.307210</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>0.385711</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.246992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03930</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>-8.926</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>99.935</td>\n",
       "      <td>0.495</td>\n",
       "      <td>2.205607e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.327024</td>\n",
       "      <td>428</td>\n",
       "      <td>0.450053</td>\n",
       "      <td>0.192193</td>\n",
       "      <td>0.030384</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.760386</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.54200</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>-6.246</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>134.001</td>\n",
       "      <td>0.275</td>\n",
       "      <td>8.756409e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.063918</td>\n",
       "      <td>141</td>\n",
       "      <td>0.290722</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.418962</td>\n",
       "      <td>0.230767</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.347208</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00364</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>-7.328</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>100.904</td>\n",
       "      <td>0.796</td>\n",
       "      <td>1.049947e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.838269</td>\n",
       "      <td>132</td>\n",
       "      <td>0.300683</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.994590</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>-5.559</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>186.752</td>\n",
       "      <td>0.709</td>\n",
       "      <td>2.109060e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>117</td>\n",
       "      <td>0.365625</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.324886</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.624069</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  energy  instrumentalness  liveness  loudness  \\\n",
       "0       0.20200         0.759   0.699          0.000131    0.4430    -5.745   \n",
       "1       0.03930         0.535   0.505          0.000000    0.0923    -8.926   \n",
       "2       0.54200         0.698   0.533          0.000000    0.3330    -6.246   \n",
       "3       0.00364         0.767   0.551          0.000000    0.0451    -7.328   \n",
       "4       0.17500         0.398   0.804          0.000000    0.1810    -5.559   \n",
       "\n",
       "   speechiness    tempo  valence    view_count  ...  avg_word_len  \\\n",
       "0       0.0307   92.960    0.907  1.118930e+09  ...      4.846395   \n",
       "1       0.2450   99.935    0.495  2.205607e+08  ...      5.327024   \n",
       "2       0.0437  134.001    0.275  8.756409e+07  ...      5.063918   \n",
       "3       0.0616  100.904    0.796  1.049947e+07  ...      4.838269   \n",
       "4       0.0451  186.752    0.709  2.109060e+07  ...      5.375000   \n",
       "\n",
       "   unique_words  vocab_richness  Rap_Street_Slang_Topic  \\\n",
       "0            98        0.307210                0.001245   \n",
       "1           428        0.450053                0.192193   \n",
       "2           141        0.290722                0.000765   \n",
       "3           132        0.300683                0.000900   \n",
       "4           117        0.365625                0.001012   \n",
       "\n",
       "   Romance_Relationships_Topic  Life_Nostalgia_Topic  \\\n",
       "0                     0.001247              0.001247   \n",
       "1                     0.030384              0.000396   \n",
       "2                     0.418962              0.230767   \n",
       "3                     0.000902              0.000901   \n",
       "4                     0.324886              0.046997   \n",
       "\n",
       "   Party_Dance_Sensuality_Topic  Love_Emotion_Sentiment_Topic  \\\n",
       "0                      0.362314                      0.385711   \n",
       "1                      0.015850                      0.760386   \n",
       "2                      0.000766                      0.347208   \n",
       "3                      0.000906                      0.994590   \n",
       "4                      0.624069                      0.001012   \n",
       "\n",
       "   Loss_Struggle_Reflection_Topic  Energy_Vibes_Epic_Topic  \n",
       "0                        0.001244                 0.246992  \n",
       "1                        0.000396                 0.000396  \n",
       "2                        0.000765                 0.000766  \n",
       "3                        0.000900                 0.000901  \n",
       "4                        0.001011                 0.001014  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data set\n",
    "df = pd.read_csv(\"model_ready_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e6ccfa5-f28b-4a86-94f7-6433e17e0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.drop(columns=['view_count'])\n",
    "\n",
    "# numeric columns only\n",
    "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "X_numeric = X[num_cols]\n",
    "\n",
    "# scale numeric columns\n",
    "X = scaler.fit_transform(X_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88dee2e-7168-4bc4-a254-ec2eefce90d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            5,395.0000\n",
       "mean       192,167,018.5800\n",
       "std        441,693,263.0710\n",
       "min                755.0000\n",
       "25%         10,632,900.5000\n",
       "50%         44,285,885.0000\n",
       "75%        171,219,462.5000\n",
       "max      6,847,227,502.0000\n",
       "Name: view_count, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive summary of continuous response\n",
    "df['view_count'].describe().apply(lambda x: f\"{x:,.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610dad74-1e11-4c1b-9166-b549249f58d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view_count_factor\n",
      "no     3551\n",
      "yes    1844\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create the target\n",
    "df['view_count_factor'] = df['view_count'].apply(\n",
    "    lambda x: 'yes' if x >= 100_000_000 else 'no'\n",
    ")\n",
    "\n",
    "# make sure it's a factor\n",
    "df['view_count_factor'] = df['view_count_factor'].astype('category')\n",
    "\n",
    "# ordered correctly\n",
    "df['view_count_factor'] = df['view_count_factor'].cat.set_categories(['no', 'yes'])\n",
    "\n",
    "y = df['view_count_factor']\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c65b7665-7706-409f-acbe-d60c3ca25cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training (70%) and testing (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c97061-9c31-4e9a-a190-161aecf9d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the algorithm\n",
    "dtree=DecisionTreeClassifier()\n",
    "\n",
    "# Generate a new model using training data only\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8fccdd-2fce-4977-94a6-538e0e495743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6491661519456454\n",
      "[[756 289]\n",
      " [279 295]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.73      0.72      0.73      1045\n",
      "         yes       0.51      0.51      0.51       574\n",
      "\n",
      "    accuracy                           0.65      1619\n",
      "   macro avg       0.62      0.62      0.62      1619\n",
      "weighted avg       0.65      0.65      0.65      1619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ea481aa-1900-45f3-ae1b-59b720292216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracies: [0.65343915 0.64021164 0.62962963 0.62433862 0.5978836  0.63492063\n",
      " 0.64721485 0.64721485 0.62864721 0.62068966]\n",
      "Mean CV accuracy: 0.6324189858672618 \n",
      "\n",
      "Best parameters from grid search: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2}\n",
      "Best CV score: 0.6806135463751357 \n",
      "\n",
      "Class distribution after undersampling:\n",
      "view_count_factor\n",
      "no     1291\n",
      "yes    1291\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Accuracy (Tree 2): 0.5793699814700433\n",
      "\n",
      "Confusion Matrix (Tree 2):\n",
      " [[623 443]\n",
      " [238 315]]\n",
      "\n",
      "Classification Report (Tree 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          no       0.72      0.58      0.65      1066\n",
      "         yes       0.42      0.57      0.48       553\n",
      "\n",
      "    accuracy                           0.58      1619\n",
      "   macro avg       0.57      0.58      0.56      1619\n",
      "weighted avg       0.62      0.58      0.59      1619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 2. Train/test split\n",
    "# ---------------------------------------------------\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=1234,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Cross-validation on the ORIGINAL (unbalanced) training data\n",
    "# ---------------------------------------------------\n",
    "classifier = DecisionTreeClassifier(random_state=1234)\n",
    "\n",
    "# IMPORTANT FIX: use X_train2, y_train2 (not X_train, y_train)\n",
    "cv_accuracies = cross_val_score(estimator=classifier, \n",
    "                                X=X_train2, \n",
    "                                y=y_train2, \n",
    "                                cv=10)\n",
    "\n",
    "print(\"Cross-validation accuracies:\", cv_accuracies)\n",
    "print(\"Mean CV accuracy:\", cv_accuracies.mean(), \"\\n\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Grid search for Decision Tree hyperparameters\n",
    "# ---------------------------------------------------\n",
    "# IMPORTANT FIX: remove n_estimators (DecisionTreeClassifier does NOT have it)\n",
    "grid_param = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1,2,3,4,5],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "# FIX: use X_train2, y_train2\n",
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "gd_sr.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"Best parameters from grid search:\", gd_sr.best_params_)\n",
    "print(\"Best CV score:\", gd_sr.best_score_, \"\\n\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. UNDERSAMPLE TRAINING DATA ONLY\n",
    "# ---------------------------------------------------\n",
    "rus2 = RandomUnderSampler(sampling_strategy='auto', random_state=1234)\n",
    "X_train_res2, y_train_res2 = rus2.fit_resample(X_train2, y_train2)\n",
    "\n",
    "print(\"Class distribution after undersampling:\")\n",
    "print(y_train_res2.value_counts(), \"\\n\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. Train final Decision Tree on UNDERSAMPLED data\n",
    "# ---------------------------------------------------\n",
    "dtree2 = DecisionTreeClassifier(random_state=1234)\n",
    "dtree2.fit(X_train_res2, y_train_res2)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7. Predict on the ORIGINAL test set\n",
    "# ---------------------------------------------------\n",
    "y_pred2 = dtree2.predict(X_test2)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. Evaluate model\n",
    "# ---------------------------------------------------\n",
    "print(\"Accuracy (Tree 2):\", accuracy_score(y_test2, y_pred2))\n",
    "print(\"\\nConfusion Matrix (Tree 2):\\n\", confusion_matrix(y_test2, y_pred2))\n",
    "print(\"\\nClassification Report (Tree 2):\\n\", classification_report(y_test2, y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
